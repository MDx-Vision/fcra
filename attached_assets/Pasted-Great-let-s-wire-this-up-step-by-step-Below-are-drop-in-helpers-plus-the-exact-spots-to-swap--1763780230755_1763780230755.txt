Great, let‚Äôs wire this up step by step.

Below are **drop-in helpers** plus the exact spots to swap `/webhook` and `/api/analyze` over to **section-based Stage 1** instead of one giant call.

---

## 1Ô∏è‚É£ Add section-splitting + merging helpers

Put these **near the top of your file**, after `truncate_for_token_limit` and `clean_credit_report_html`, and before `analyze_with_claude`.

```python
# Heuristic markers for common 3-bureau report sections
SECTION_MARKERS = {
    "tradelines": [
        "ACCOUNTS", "TRADELINES", "REVOLVING ACCOUNTS", "INSTALLMENT ACCOUNTS",
        "OPEN ACCOUNTS", "CLOSED ACCOUNTS"
    ],
    "collections": [
        "COLLECTION", "COLLECTIONS"
    ],
    "public_records": [
        "PUBLIC RECORD", "PUBLIC RECORDS", "BANKRUPTCIES", "JUDGMENTS", "TAX LIENS"
    ],
    "inquiries": [
        "INQUIRIES", "CREDIT INQUIRIES", "REGULAR INQUIRIES", "HARD INQUIRIES"
    ],
}


def split_report_into_sections(text: str) -> dict:
    """
    Split cleaned report text into logical sections based on common headings.

    Returns:
        {
          "tradelines": "....",
          "collections": "....",
          "public_records": "....",
          "inquiries": "...."
        }
    Empty sections are omitted.
    """
    sections = {k: [] for k in SECTION_MARKERS.keys()}
    current_key = None

    if not text:
        return {}

    lines = text.splitlines()
    for line in lines:
        upper = line.strip().upper()

        # Check if this line looks like a section heading
        new_key = None
        for key, markers in SECTION_MARKERS.items():
            if any(m in upper for m in markers):
                new_key = key
                break

        if new_key:
            current_key = new_key
            # Also store the heading line itself for context
            sections[current_key].append(line)
        elif current_key:
            sections[current_key].append(line)

    # Join and drop empty sections
    finalized = {}
    for key, lines in sections.items():
        joined = "\n".join(lines).strip()
        if joined:
            finalized[key] = joined

    print("üìö split_report_into_sections:", {k: len(v) for k, v in finalized.items()})
    return finalized


def merge_standing(standings: list) -> dict:
    """
    Merge multiple standing blocks from different sections into one.
    Simple rules:
      - Boolean flags are OR'ed
      - Counts are summed
      - Text fields are concatenated with separators
    """
    if not standings:
        return {
            "has_concrete_harm": False,
            "concrete_harm_type": "",
            "harm_details": "",
            "has_dissemination": False,
            "dissemination_details": "",
            "has_causation": False,
            "causation_details": "",
            "denial_letters_count": 0,
            "adverse_action_notices_count": 0,
        }

    merged = {
        "has_concrete_harm": False,
        "concrete_harm_type": [],
        "harm_details": [],
        "has_dissemination": False,
        "dissemination_details": [],
        "has_causation": False,
        "causation_details": [],
        "denial_letters_count": 0,
        "adverse_action_notices_count": 0,
    }

    for s in standings:
        if not s:
            continue
        merged["has_concrete_harm"] = merged["has_concrete_harm"] or s.get("has_concrete_harm", False)
        merged["has_dissemination"] = merged["has_dissemination"] or s.get("has_dissemination", False)
        merged["has_causation"] = merged["has_causation"] or s.get("has_causation", False)

        if s.get("concrete_harm_type"):
            merged["concrete_harm_type"].append(str(s.get("concrete_harm_type")))
        if s.get("harm_details"):
            merged["harm_details"].append(str(s.get("harm_details")))
        if s.get("dissemination_details"):
            merged["dissemination_details"].append(str(s.get("dissemination_details")))
        if s.get("causation_details"):
            merged["causation_details"].append(str(s.get("causation_details")))

        merged["denial_letters_count"] += int(s.get("denial_letters_count", 0) or 0)
        merged["adverse_action_notices_count"] += int(s.get("adverse_action_notices_count", 0) or 0)

    # Join text fields
    return {
        "has_concrete_harm": merged["has_concrete_harm"],
        "concrete_harm_type": " | ".join(merged["concrete_harm_type"]),
        "harm_details": "\n\n".join(merged["harm_details"]),
        "has_dissemination": merged["has_dissemination"],
        "dissemination_details": "\n\n".join(merged["dissemination_details"]),
        "has_causation": merged["has_causation"],
        "causation_details": "\n\n".join(merged["causation_details"]),
        "denial_letters_count": merged["denial_letters_count"],
        "adverse_action_notices_count": merged["adverse_action_notices_count"],
    }


def merge_actual_damages(damages_list: list) -> dict:
    """
    Merge multiple 'actual_damages' blocks by summing numeric fields.
    """
    merged = {
        "credit_denials_amount": 0,
        "higher_interest_amount": 0,
        "credit_monitoring_amount": 0,
        "time_stress_amount": 0,
        "other_actual_amount": 0,
        "notes": "",
    }

    notes = []
    for d in damages_list:
        if not d:
            continue
        merged["credit_denials_amount"] += float(d.get("credit_denials_amount", 0) or 0)
        merged["higher_interest_amount"] += float(d.get("higher_interest_amount", 0) or 0)
        merged["credit_monitoring_amount"] += float(d.get("credit_monitoring_amount", 0) or 0)
        merged["time_stress_amount"] += float(d.get("time_stress_amount", 0) or 0)
        merged["other_actual_amount"] += float(d.get("other_actual_amount", 0) or 0)
        if d.get("notes"):
            notes.append(str(d["notes"]))

    merged["notes"] = "\n\n".join(notes)
    return merged


def merge_litigation_data(section_results: list) -> dict:
    """
    section_results: list of dicts from extract_litigation_data, one per section.

    Returns a single litigation_data dict compatible with auto_populate_litigation_database:
      {
        "violations": [...],
        "standing": {...},
        "actual_damages": {...}
      }
    """
    all_violations = []
    standings = []
    damages_blocks = []

    for r in section_results:
        if not r:
            continue
        v_list = r.get("violations", []) or []
        s = r.get("standing", {}) or {}
        a = r.get("actual_damages", {}) or {}

        all_violations.extend(v_list)
        standings.append(s)
        damages_blocks.append(a)

    merged = {
        "violations": all_violations,
        "standing": merge_standing(standings),
        "actual_damages": merge_actual_damages(damages_blocks),
    }
    print(f"üß© merge_litigation_data: {len(all_violations)} total violations merged")
    return merged
```

---

## 2Ô∏è‚É£ Add `run_stage1_for_all_sections(...)`

This will orchestrate multiple Stage 1 calls, one per section, and return a combined result.

Add this **right after** `merge_litigation_data`:

```python
def run_stage1_for_all_sections(
    client_name,
    cmm_id,
    provider,
    credit_report_text,
    analysis_mode="manual",
    dispute_round=1,
    previous_letters="",
    bureau_responses="",
    dispute_timeline=""
):
    """
    Split the cleaned report into sections and run Stage 1 analysis per section.
    Returns:
        {
          'success': True/False,
          'combined_analysis': str,
          'litigation_data': {...},  # merged
          'per_section': [
              {
                'section_name': 'tradelines',
                'analysis': '...',
                'raw_litigation_data': {...}
              },
              ...
          ],
          'tokens_used': int,
          'cost': float,
          'cache_read': bool
        }
    """
    sections = split_report_into_sections(credit_report_text)
    if not sections:
        return {
            'success': False,
            'error': 'Could not detect any recognizable sections in report',
        }

    all_section_results = []
    combined_analysis_parts = []
    total_tokens = 0
    total_cost = 0.0
    any_cache_read = False

    for section_name, section_text in sections.items():
        print(f"\nüîç Stage 1 analysis for section: {section_name} "
              f"({len(section_text):,} chars)")

        result = analyze_with_claude(
            client_name=client_name,
            cmm_id=cmm_id,
            provider=provider,
            credit_report_html=section_text,
            analysis_mode=analysis_mode,
            dispute_round=dispute_round,
            previous_letters=previous_letters,
            bureau_responses=bureau_responses,
            dispute_timeline=dispute_timeline,
            stage=1
        )

        if not result.get('success'):
            print(f"‚ùå Section {section_name} failed: {result.get('error')}")
            # We record the failure but keep going with other sections
            all_section_results.append({
                'section_name': section_name,
                'analysis': '',
                'raw_litigation_data': None,
                'error': result.get('error'),
            })
            continue

        analysis_text = result.get('analysis', '') or ''
        litigation_data = extract_litigation_data(analysis_text)

        combined_analysis_parts.append(
            f"\n\n{'='*80}\nSECTION: {section_name.upper()}\n{'='*80}\n\n{analysis_text}"
        )

        all_section_results.append({
            'section_name': section_name,
            'analysis': analysis_text,
            'raw_litigation_data': litigation_data,
        })

        total_tokens += int(result.get('tokens_used', 0) or 0)
        total_cost += float(result.get('cost', 0.0) or 0.0)
        any_cache_read = any_cache_read or bool(result.get('cache_read', False))

    # Filter out sections that returned no data
    parsed_litigation_blocks = [
        r['raw_litigation_data']
        for r in all_section_results
        if r.get('raw_litigation_data')
    ]

    if not parsed_litigation_blocks:
        return {
            'success': False,
            'error': 'No valid litigation_data extracted from any section',
            'combined_analysis': "\n\n".join(combined_analysis_parts),
            'per_section': all_section_results,
            'tokens_used': total_tokens,
            'cost': total_cost,
            'cache_read': any_cache_read
        }

    merged_litigation = merge_litigation_data(parsed_litigation_blocks)

    return {
        'success': True,
        'combined_analysis': "\n\n".join(combined_analysis_parts),
        'litigation_data': merged_litigation,
        'per_section': all_section_results,
        'tokens_used': total_tokens,
        'cost': total_cost,
        'cache_read': any_cache_read
    }
```

---

## 3Ô∏è‚É£ Wire `/webhook` to use section-based Stage 1

Right now in `/webhook` you do:

```python
credit_report_html = data.get('creditReportHTML', '')
...
credit_report_html = clean_credit_report_html(credit_report_html)
...
analysis = analyze_with_claude(
    client_name=client_name,
    cmm_id=cmm_contact_id,
    provider=credit_provider,
    credit_report_html=credit_report_html,
    analysis_mode=analysis_mode,
    dispute_round=dispute_round,
    previous_letters=previous_letters,
    bureau_responses=bureau_responses,
    dispute_timeline=dispute_timeline
)
```

Change just the **analysis part** to:

```python
# Analyze with Claude API (section-based Stage 1)
analysis = run_stage1_for_all_sections(
    client_name=client_name,
    cmm_id=cmm_contact_id,
    provider=credit_provider,
    credit_report_text=credit_report_html,
    analysis_mode=analysis_mode,
    dispute_round=dispute_round,
    previous_letters=previous_letters,
    bureau_responses=bureau_responses,
    dispute_timeline=dispute_timeline
)

if analysis.get('success'):
    report['analysis'] = analysis.get('combined_analysis', '')
    report['processed'] = True
    print(f"‚úÖ FCRA Section-based Analysis completed for {client_name}")
else:
    report['analysis_error'] = analysis.get('error', 'Unknown error')
    print(f"‚ö†Ô∏è Section-based analysis failed: {analysis.get('error')}")
```

Everything else in `/webhook` can stay the same.

---

## 4Ô∏è‚É£ Wire `/api/analyze` to use sections too

In `analyze_and_generate_letters`, replace the Stage 1 call:

```python
# Use analyze_with_claude function - STAGE 1 only (violations/standing/damages analysis)
result = analyze_with_claude(
    client_name=client_name,
    cmm_id=data.get('cmmContactId', ''),
    provider=credit_provider,
    credit_report_html=credit_report_html,
    analysis_mode='manual',  # Always manual for initial review
    dispute_round=dispute_round,
    stage=1  # STAGE 1: Just violations/standing/damages analysis
)
```

with:

```python
# Section-based Stage 1 analysis
result = run_stage1_for_all_sections(
    client_name=client_name,
    cmm_id=data.get('cmmContactId', ''),
    provider=credit_provider,
    credit_report_text=credit_report_html,
    analysis_mode='manual',
    dispute_round=dispute_round,
    previous_letters=data.get('previousLetters', ''),
    bureau_responses=data.get('bureauResponses', ''),
    dispute_timeline=data.get('disputeTimeline', '')
)

if not result.get('success'):
    return jsonify({'success': False, 'error': result.get('error', 'Analysis failed')}), 500
```

Then, further down where you currently do:

```python
analysis_record = Analysis(
    ...
    stage_1_analysis=result.get('analysis', ''),  # Store Stage 1 results
    cost=result.get('cost', 0),
    tokens_used=result.get('tokens_used', 0),
    cache_read=result.get('cache_read', False)
)
```

Change it to:

```python
analysis_record = Analysis(
    ...
    stage_1_analysis=result.get('combined_analysis', ''),  # Combined per-section Stage 1
    cost=result.get('cost', 0),
    tokens_used=result.get('tokens_used', 0),
    cache_read=result.get('cache_read', False)
)
```

And where you currently do:

```python
analysis_text = result.get('analysis', '')
litigation_data = extract_litigation_data(analysis_text)
if litigation_data:
    ...
```

replace with:

```python
analysis_text = result.get('combined_analysis', '')
litigation_data = result.get('litigation_data')  # already merged
if litigation_data:
    print(f"\nüéØ Litigation data found across sections! Auto-populating database...")
    auto_populate_litigation_database(
        analysis_id=analysis_record.id,
        client_id=client.id,
        litigation_data=litigation_data,
        db=db
    )
else:
    print(f"\n‚ö†Ô∏è No merged litigation data found in section-based analysis")
```

Stage 2 (`approve_analysis_stage_1`) can stay as is, since it works off `analysis.stage_1_analysis` and not the raw report.

---

If you‚Äôd like next, I can:

* Add a small flag in the DB to store the **section breakdown**, or
* Tighten the `SECTION_MARKERS` for whatever credit provider formats you use most (IdentityIQ, SmartCredit, etc.) so splitting is even more accurate.
